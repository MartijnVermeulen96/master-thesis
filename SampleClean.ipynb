{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample cleaning scripts\n",
    "\n",
    "This notebook contains numerous sample usages of the error detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['beers',\n",
       " 'company',\n",
       " 'eeg',\n",
       " 'flights',\n",
       " 'hospital',\n",
       " 'kdd',\n",
       " 'movie',\n",
       " 'movies',\n",
       " 'rayyan',\n",
       " 'restaurant',\n",
       " 'restaurants',\n",
       " 'salaries',\n",
       " 'salaries_small',\n",
       " 'tax',\n",
       " 'toy',\n",
       " 'university',\n",
       " 'uscensus']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of datasets: 17\n"
     ]
    }
   ],
   "source": [
    "import errorAPI\n",
    "import time\n",
    "\n",
    "list_of_datasets = errorAPI.Dataset.list_datasets()\n",
    "print(\"Available datasets:\")\n",
    "display(list_of_datasets)\n",
    "print(\"Amount of datasets:\",len(list_of_datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing available tools and load a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools:\n",
      "['ActiveClean', 'dBoost', 'FAHES', 'FDchecker', 'ForbiddenItemSets', 'KATARA', 'Raha', 'Regex']\n",
      "Data quality: 0.835458317615994\n",
      "Num rows: 2410\n"
     ]
    }
   ],
   "source": [
    "creator = errorAPI.ToolCreator()\n",
    "tools = creator.list_tools()\n",
    "dataset_dictionary = {\n",
    "    \"name\": \"beers\",\n",
    "}\n",
    "d = errorAPI.Dataset(dataset_dictionary)\n",
    "print(\"Data quality:\", d.get_data_quality())\n",
    "print(\"Num rows:\", len(d.dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beers', 'company', 'eeg', 'flights', 'hospital', 'kdd', 'movie', 'movies', 'rayyan', 'restaurant', 'restaurants', 'salaries', 'salaries_small', 'tax', 'toy', 'university', 'uscensus']\n"
     ]
    }
   ],
   "source": [
    "print(list_of_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default tool configs\n",
    "Run the default tool configuration on the specified dataset and show its help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for tool_name in tools:\n",
    "        print(\"-=\"*10)\n",
    "        tool = creator.createTool(tool_name, [])\n",
    "        tool.help()\n",
    "        results = tool.run(d)\n",
    "        try:\n",
    "            errorAPI.Dataset.print_scores(d, results)\n",
    "        except:\n",
    "            pass\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example tool configs\n",
    "Run more example configurations specified for the different tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1: 0\n",
      "Tool: \n",
      "Best config: {}\n"
     ]
    }
   ],
   "source": [
    "# run_examples_from_tools = [\n",
    "#     \"dBoost\", \n",
    "#     \"FAHES\", \n",
    "#     \"Raha\",\n",
    "#     \"ForbiddenItemSets\",\n",
    "# ]\n",
    "run_examples_from_tools = []\n",
    "\n",
    "best_tool = \"\"\n",
    "best_config = {}\n",
    "max_f1 = 0\n",
    "\n",
    "for tool_name in run_examples_from_tools:\n",
    "    for config in creator.createTool(tool_name, []).example_configurations:\n",
    "        tool = creator.createTool(tool_name, config)\n",
    "        results = tool.run(d)\n",
    "        \n",
    "        (cprec, crec, cf1, prec, rec, f1) = errorAPI.Dataset.print_scores(d, results)\n",
    "        \n",
    "        if cf1 > max_f1:\n",
    "            best_tool = tool_name\n",
    "            best_config = config\n",
    "            max_f1 = cf1\n",
    "#         break\n",
    "\n",
    "print(\"Max F1:\", max_f1)\n",
    "print(\"Tool:\", best_tool)\n",
    "print(\"Best config:\", best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show sample repairs\n",
    "Show the differences of the detect errors with the real repaired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the edited values\n",
    "\n",
    "if False:\n",
    "    d.create_repaired_dataset(results)\n",
    "    my_repaired_index = (d.repaired_dataframe == \"JUST A DUMMY VALUE\").any(axis=1)\n",
    "\n",
    "    print(\"Original:\")\n",
    "    display(d.dataframe[my_repaired_index].head(5))\n",
    "    \n",
    "    print(\"Attempt to detect:\")\n",
    "    display(d.repaired_dataframe[my_repaired_index].head(5))\n",
    "    \n",
    "    print(\"Real cleaned:\")\n",
    "    d.create_repaired_dataset(d.actual_errors_dictionary)\n",
    "    display(d.repaired_dataframe[my_repaired_index].head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out single tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dictionary = {\n",
    "    \"name\": \"uscensus\",\n",
    "}\n",
    "d = errorAPI.Dataset(dataset_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration arguments:\n",
      "Examples: \n"
     ]
    }
   ],
   "source": [
    "##### Try out\n",
    "if True:\n",
    "    tool_name = \"ForbiddenItemSets\"\n",
    "    \n",
    "    config = {\n",
    "        \"Tau\": 0.7\n",
    "    }\n",
    "#     config = {\"Params\": [\"mixture\", \"3\", \"0.7\"]}\n",
    "#     config = {\"Params\": [\"histogram\", \"0.1\", \"0.1\"]}\n",
    "#     config = {\"Params\": [\"gaussian\", \"1.5\"]}\n",
    "#     config = {}\n",
    "    start = time.time()\n",
    "    tool = creator.createTool(tool_name, config)\n",
    "    tool.help()\n",
    "    results = tool.run(d)\n",
    "    print(\"Results len:\", len(results))\n",
    "    errorAPI.Dataset.print_scores(d, results)\n",
    "    print(\"This took {:.2f} seconds\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(found_left_col, \"<=>\", found_left_val)\n",
    "print(found_right_col, \"<=>\", found_right_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
